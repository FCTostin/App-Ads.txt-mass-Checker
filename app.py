import streamlit as st
import pandas as pd
import requests
from concurrent.futures import ThreadPoolExecutor, as_completed
from urllib.parse import urlparse
import re

# --- 1. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—ã ---
st.set_page_config(
    page_title="App-ads.txt Checker", 
    layout="wide", 
    page_icon="üõ°Ô∏è"
)

st.markdown("""
    <style>
    .stApp { background-color: #0e1117; color: #fafafa; }
    .stTextArea textarea { background-color: #262730; color: #ffffff; border: 1px solid #444; }
    div[data-testid="stDataFrame"] { background-color: #262730; }
    </style>
""", unsafe_allow_html=True)

st.title("üõ°Ô∏è App-ads.txt Checker")
st.markdown("Verifies file availability (checking www/non-www) and counts **valid IAB ad records**.")

# --- 2. –ù–∞—Å—Ç—Ä–æ–π–∫–∞ —Å–µ—Å—Å–∏–∏ (–∏–º–∏—Ç–∞—Ü–∏—è –±—Ä–∞—É–∑–µ—Ä–∞) ---
def get_session():
    session = requests.Session()
    # –ú–∞–∫—Å–∏–º–∞–ª—å–Ω–æ –ø–æ—Ö–æ–∂–∏–µ –Ω–∞ –Ω–∞—Å—Ç–æ—è—â–∏–π Chrome –∑–∞–≥–æ–ª–æ–≤–∫–∏
    session.headers.update({
        'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/121.0.0.0 Safari/537.36',
        'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/avif,image/webp,*/*;q=0.8',
        'Accept-Language': 'en-US,en;q=0.9',
        'Accept-Encoding': 'gzip, deflate, br',
        'Connection': 'keep-alive',
        'Upgrade-Insecure-Requests': '1',
        'Sec-Ch-Ua': '"Not A(Brand";v="99", "Google Chrome";v="121", "Chromium";v="121"',
        'Sec-Ch-Ua-Mobile': '?0',
        'Sec-Ch-Ua-Platform': '"Windows"',
    })
    return session

# --- 3. –û—á–∏—Å—Ç–∫–∞ –¥–æ–º–µ–Ω–∞ –∏–∑ –≤–≤–æ–¥–∞ ---
def clean_domain(url_input):
    # –£–±–∏—Ä–∞–µ–º –∫–∞–≤—ã—á–∫–∏ –∏ –ª–∏—à–Ω–∏–µ –ø—Ä–æ–±–µ–ª—ã
    url_input = url_input.strip().replace('"', '').replace("'", "")
    
    # –î–æ–±–∞–≤–ª—è–µ–º —Å—Ö–µ–º—É –¥–ª—è –ø–∞—Ä—Å–∏–Ω–≥–∞, –µ—Å–ª–∏ –µ—ë –Ω–µ—Ç
    if not url_input.startswith(("http://", "https://")):
        url_input = "http://" + url_input
        
    try:
        parsed = urlparse(url_input)
        domain = parsed.netloc if parsed.netloc else parsed.path.split('/')[0]
        # –£–±–∏—Ä–∞–µ–º www. –≤ –Ω–∞—á–∞–ª–µ, —á—Ç–æ–±—ã –∞–ª–≥–æ—Ä–∏—Ç–º –ø–µ—Ä–µ–±–æ—Ä–∞ —Å–∞–º —Ä–µ—à–∞–ª, –¥–æ–±–∞–≤–ª—è—Ç—å –µ–≥–æ –∏–ª–∏ –Ω–µ—Ç
        return domain.lower().replace("www.", "").strip()
    except:
        return url_input

# --- 4. –ü–∞—Ä—Å–∏–Ω–≥ —Å–æ–¥–µ—Ä–∂–∏–º–æ–≥–æ —Ñ–∞–π–ª–∞ (IAB Logic) ---
def count_valid_lines(content):
    valid_count = 0
    
    # 1. –£–¥–∞–ª—è–µ–º BOM (Byte Order Mark), –∫–æ—Ç–æ—Ä—ã–π —á–∞—Å—Ç–æ –ª–æ–º–∞–µ—Ç –ø–µ—Ä–≤—É—é —Å—Ç—Ä–æ–∫—É
    content = content.replace('\ufeff', '')
    
    # 2. –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º –ø–µ—Ä–µ–Ω–æ—Å—ã —Å—Ç—Ä–æ–∫ (Windows/Unix)
    lines = content.replace('\r\n', '\n').replace('\r', '\n').splitlines()
    
    for line in lines:
        # –£–±–∏—Ä–∞–µ–º –∫–æ–º–º–µ–Ω—Ç–∞—Ä–∏–∏
        clean_line = line.split('#')[0].strip()
        
        if not clean_line:
            continue
            
        parts = [p.strip() for p in clean_line.split(',')]
        
        # –°—Ç–∞–Ω–¥–∞—Ä—Ç IAB: Domain, Account ID, Type (–º–∏–Ω–∏–º—É–º 3 –ø–æ–ª—è)
        if len(parts) >= 3:
            # –û—á–∏—â–∞–µ–º –ø–æ–ª–µ —Ç–∏–ø–∞ (DIRECT/RESELLER) –æ—Ç –Ω–µ–≤–∏–¥–∏–º—ã—Ö —Å–∏–º–≤–æ–ª–æ–≤
            # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ –±—É–∫–≤—ã A-Z
            relationship = re.sub(r'[^A-Z]', '', parts[2].upper())
            
            if relationship in ["DIRECT", "RESELLER"]:
                valid_count += 1
                
    return valid_count

# --- 5. –û—Å–Ω–æ–≤–Ω–∞—è –ª–æ–≥–∏–∫–∞ –ø—Ä–æ–≤–µ—Ä–∫–∏ –¥–æ–º–µ–Ω–∞ ---
def check_domain_smart(domain):
    session = get_session()
    
    # –ì–µ–Ω–µ—Ä–∏—Ä—É–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã. –ü—Ä–∏–æ—Ä–∏—Ç–µ—Ç: HTTPS, WWW, –ø–æ—Ç–æ–º HTTP
    urls_to_try = [
        f"https://{domain}/app-ads.txt",
        f"https://www.{domain}/app-ads.txt",
        f"http://{domain}/app-ads.txt",
        f"http://www.{domain}/app-ads.txt"
    ]
    
    for url in urls_to_try:
        try:
            # verify=True –≤–∞–∂–Ω–æ –¥–ª—è –±–µ–∑–æ–ø–∞—Å–Ω–æ—Å—Ç–∏, –Ω–æ –µ—Å–ª–∏ –ø–∞–¥–∞–µ—Ç - –æ–±—Ä–∞–±–æ—Ç–∞–µ–º –Ω–∏–∂–µ
            response = session.get(url, timeout=10, allow_redirects=True, verify=True)
            
            if response.status_code == 200:
                # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–¥–∏—Ä–æ–≤–∫—É –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏
                response.encoding = response.apparent_encoding
                content = response.text
                
                # –ó–∞—â–∏—Ç–∞ –æ—Ç HTML-–∑–∞–≥–ª—É—à–µ–∫ (–∏–Ω–æ–≥–¥–∞ —Å–µ—Ä–≤–µ—Ä –æ—Ç–¥–∞–µ—Ç 200 OK, –Ω–æ –≤–Ω—É—Ç—Ä–∏ "Page not found")
                if "<html" in content.lower()[:300] or "<!doctype" in content.lower()[:300]:
                    continue 
                
                valid_lines = count_valid_lines(content)
                return url, "Valid", valid_lines
                
        except requests.exceptions.SSLError:
            # –ï—Å–ª–∏ SSL –æ—à–∏–±–∫–∞, –ø—Ä–æ–±—É–µ–º –±–µ–∑ –ø—Ä–æ–≤–µ—Ä–∫–∏ —Å–µ—Ä—Ç–∏—Ñ–∏–∫–∞—Ç–∞
            try:
                response = session.get(url, timeout=10, allow_redirects=True, verify=False)
                if response.status_code == 200:
                    response.encoding = response.apparent_encoding
                    content = response.text
                    if "<html" not in content.lower()[:300]:
                        valid_lines = count_valid_lines(content)
                        return url, "Valid", valid_lines
            except:
                pass
        except Exception:
            pass
            
    # –ï—Å–ª–∏ –ø–µ—Ä–µ–±—Ä–∞–ª–∏ –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –∏ –Ω–µ –Ω–∞—à–ª–∏
    return f"https://{domain}/app-ads.txt", "Error / Not Found", 0

# --- 6. –ò–Ω—Ç–µ—Ä—Ñ–µ–π—Å ---
input_text = st.text_area(
    "Insert domain list (1 per line)", 
    height=300, 
    placeholder="hyperhippo.com\ngoogle.com"
)

if st.button("Run Check"):
    if not input_text.strip():
        st.warning("The list is empty.")
    else:
        raw_lines = [line.strip() for line in input_text.splitlines() if line.strip()]
        
        tasks = []
        for idx, line in enumerate(raw_lines):
            domain = clean_domain(line)
            tasks.append((idx, domain))
            
        st.info(f"Analyzing {len(tasks)} domains...")
        
        progress_bar = st.progress(0)
        status_text = st.empty()
        unsorted_results = []
        
        # –ú–Ω–æ–≥–æ–ø–æ—Ç–æ—á–Ω–æ—Å—Ç—å –¥–ª—è —É—Å–∫–æ—Ä–µ–Ω–∏—è
        with ThreadPoolExecutor(max_workers=20) as executor:
            future_to_idx = {
                executor.submit(check_domain_smart, domain): idx 
                for idx, domain in tasks
            }
            
            completed = 0
            for future in as_completed(future_to_idx):
                idx = future_to_idx[future]
                try:
                    url, status, lines = future.result()
                except Exception:
                    # Fallback –Ω–∞ —Å–ª—É—á–∞–π –∫—Ä–∏—Ç–∏—á–µ—Å–∫–æ–π –æ—à–∏–±–∫–∏ –≤ –ø–æ—Ç–æ–∫–µ
                    orig_domain = tasks[idx][1]
                    url = f"https://{orig_domain}/app-ads.txt"
                    status = "Error"
                    lines = 0
                
                unsorted_results.append({
                    "Original_Index": idx,
                    "App-ads Link": url,
                    "Status": status,
                    "Valid Lines": lines
                })
                
                completed += 1
                progress_bar.progress(completed / len(tasks))
                status_text.text(f"Processed: {completed}/{len(tasks)}")
        
        progress_bar.empty()
        status_text.empty()
        
        # –°–±–æ—Ä–∫–∞ —Ç–∞–±–ª–∏—Ü—ã —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–≤
        df = pd.DataFrame(unsorted_results)
        df = df.sort_values(by="Original_Index").drop(columns=["Original_Index"])
        
        st.subheader("Results")
        
        def highlight_row(val):
            if val == "Valid":
                return 'color: #4CAF50; font-weight: bold'
            return 'color: #FF5252; font-weight: bold'
            
        st.dataframe(
            df.style.map(highlight_row, subset=['Status']),
            use_container_width=True,
            hide_index=True,
            column_config={
                "App-ads Link": st.column_config.LinkColumn("App-ads Link"),
                "Valid Lines": st.column_config.NumberColumn("Valid Lines (IAB)", help="Number of records matching IAB standards")
            }
        )
        
        csv_data = df.to_csv(index=False).encode('utf-8')
        st.download_button("üíæ Download Report (CSV)", csv_data, "app_ads_check_results.csv", "text/csv")
